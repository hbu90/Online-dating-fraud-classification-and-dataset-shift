{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e33cb2e",
   "metadata": {},
   "source": [
    "## Real online dating profile download script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56deeeb9",
   "metadata": {},
   "source": [
    "The below script has been sourced, with amendments, from the following repository: https://github.com/gsuareztangil/automatic-romancescam-digger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe9b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm \n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "IMAGEDIR='images_real'\n",
    "PROFILES='dating_real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569b11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iurlrx = re.compile('.* background-image: url\\(([^\\)]+)\\)')\n",
    "\n",
    "remap = {'I am' : 'gender',\n",
    "         'Age' : 'age',\n",
    "         'City' : 'location',\n",
    "         'Marital status' : 'status',\n",
    "         'Username' : 'username',\n",
    "         'Ethnicity' : 'ethnicity',\n",
    "         'Occupation' : 'occupation',\n",
    "         'About me' : 'description',\n",
    "         'My match\\'s age' : 'match_age',\n",
    "         'Children' : 'children',\n",
    "         'Sexual Orientation' : 'orientation',\n",
    "         'Religion' : 'religion',\n",
    "         'Do you smoke' : 'smoking',\n",
    "         'Do you drink' : 'drinking',\n",
    "         'Here for' : 'intent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(url):\n",
    "    \"\"\" Take a URL, generate a unique filename, save \n",
    "        the image to said file and return the filename.\"\"\"\n",
    "    \n",
    "    ext = url.split('.')[-1]\n",
    "    filename = os.getcwd()+os.sep+IMAGEDIR+os.sep+hashlib.md5(url.encode('utf-8')).hexdigest()+'.'+ext\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        return filename\n",
    "    try:\n",
    "        content = urlopen(url).read()\n",
    "        f = open(filename,'wb') \n",
    "        f.write(content)\n",
    "        f.close()\n",
    "    except e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e9e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_profile(inhandle, outfile):\n",
    "    \"\"\"Scrape an input scamdiggers page for the profile content\n",
    "    of the scammer. \"\"\"\n",
    "    \n",
    "    # Read file.\n",
    "    soup = BeautifulSoup(inhandle.read(), 'html.parser')\n",
    "\n",
    "    pfnode = soup.find('div', {'class':'profile-BASE_CMP_UserViewWidget'})\n",
    "    avnode = soup.find(id='avatar_console_image')\n",
    "\n",
    "    # Pull the provided profile data out.\n",
    "    rows = pfnode.findAll('tr')\n",
    "    labels = {}\n",
    "    for row in rows:\n",
    "        lab = row.find('td',{'class':'ow_label'})\n",
    "        val = row.find('td',{'class':'ow_value'})\n",
    "        if lab:\n",
    "            labels[lab.get_text()] = val.get_text().strip()\n",
    "\n",
    "    profile = {}\n",
    "\n",
    "    # Populate our own profile structure.\n",
    "    for lab in remap:\n",
    "        if lab in labels:\n",
    "            profile[remap[lab]] = labels[lab]\n",
    "        else:\n",
    "            profile[remap[lab]] = \"-\"\n",
    "  \n",
    "    # Tweak for consistency.\n",
    "    profile['gender'] = profile['gender'].lower()\n",
    "\n",
    "    # Extract avatar image.\n",
    "    img = iurlrx.match(avnode.attrs['style']).group(1)\n",
    "    profile['images'] = [save_image(img)]\n",
    "\n",
    "    # Save output.\n",
    "    json.dump(profile, open(outfile,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43949b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_profiles(inhandle):\n",
    "    \"\"\" Extract all the profile page links from\n",
    "    this index page. \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(inhandle.read(), 'html.parser')\n",
    "\n",
    "    urls = []\n",
    "    for node in soup.findAll('div',  {'class':'ow_user_list_data'}):\n",
    "        try:\n",
    "            urls.append(node.find('a')['href'])\n",
    "        except:\n",
    "            pass\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94011c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_profiles(inhandle):\n",
    "    \"\"\" Extract all the latest activity from\n",
    "    this index page. \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(inhandle.read(), 'html.parser')\n",
    "    activity = []\n",
    "    \n",
    "    for node in soup.findAll('div',  {'class':'ow_user_list_data'}):\n",
    "        try:\n",
    "            name = node.find('a')['href']\n",
    "            last_active = node.find('span', {\"class\":\"ow_remark\"}).get_text()\n",
    "            activity.append([name, last_active])\n",
    "        except:\n",
    "            pass\n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86dc35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(urls):\n",
    "    \n",
    "    for url in tqdm(urls):\n",
    "        uid = url[0][34:]\n",
    "        outfile=os.getcwd()+os.sep+PROFILES+os.sep+uid+'.json'\n",
    "        \n",
    "        jitter = random.choice([0,1])\n",
    "        try:\n",
    "            urlhandle = urlopen(url[0])\n",
    "            scrape_profile(urlhandle, outfile)\n",
    "            time.sleep(1+jitter)\n",
    "        except Exception as e:\n",
    "            print(\"Exception when handling {}\".format(url))\n",
    "            print(e)\n",
    "\n",
    "    print(\"Scraping complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e1cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin URL harvesting.\n",
      "Harvesting complete. 0 URLs to scrape.\n",
      "11441.6574\n"
     ]
    }
   ],
   "source": [
    "# Store the latest activity timestamps in a csv format. \n",
    "\n",
    "urls = []\n",
    "activity_log = []\n",
    "urlstr=\"http://datingnmore.com/site/users/latest?page={}\" \n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(\"Begin URL harvesting.\")\n",
    "\n",
    "for i in range(1,3245): \n",
    "    url = urlstr.format(i)\n",
    "    jitter = random.choice([0,1])\n",
    "    try:\n",
    "        urlhandle = urlopen(url)\n",
    "        latest_activity = activity_profiles(urlhandle)\n",
    "        activity_log += latest_activity\n",
    "        time.sleep(1+jitter)\n",
    "    except Exception as e:\n",
    "        print(\"Exception when handling {}\".format(url))\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "print(\"Harvesting complete. {} URLs to scrape.\".format(len(urls)))\n",
    "print(time.perf_counter()-start_time)\n",
    "\n",
    "pd.DataFrame(activity_log, columns = [\"URL\", \"Last_activity\"]).T.to_csv(\"activity_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31c515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the urls.\n",
    "# This allows the scraping to be done in batches.\n",
    "\n",
    "urls = pd.read_csv(\"URL_list.csv\")\n",
    "urls = urls.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f33b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8248448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▌                                                                 | 936/6250 [41:53<3:08:42,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/issis']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▎                                                        | 1460/6250 [1:05:29<3:14:27,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Angelmar']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▎                                                      | 1634/6250 [1:13:26<3:03:32,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/gem56']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▏                                                   | 1872/6250 [1:24:10<2:44:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/sandyb23']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▍                                                | 2149/6250 [1:36:33<2:55:50,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Geir74']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████▏                                     | 3057/6250 [2:17:22<1:51:17,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Goodyear73']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████▋                                     | 3103/6250 [2:19:28<2:01:02,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Joana14']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▎                                    | 3156/6250 [2:22:00<1:57:31,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Shirlene']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████                               | 3636/6250 [2:43:46<1:46:33,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/marcusa']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████▋                              | 3694/6250 [2:46:24<1:38:48,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/laurasofia']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████                        | 4233/6250 [3:11:03<1:11:21,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Loveable12345']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████▎                      | 4338/6250 [3:15:49<1:14:29,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Monica2018']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████▋                   | 4624/6250 [3:28:51<1:01:19,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Poly97']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████▊      | 5742/6250 [4:19:22<18:22,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception when handling ['https://datingnmore.com/site/user/Sladjaphx']\n",
      "'NoneType' object has no attribute 'findAll'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6250/6250 [4:42:46<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete.\n",
      "16966.2554971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the real profile download. Use the urls list indices to specify the profiles to download. \n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(start_time)\n",
    "scrape(urls[33750:40000])\n",
    "\n",
    "print(time.perf_counter()-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
